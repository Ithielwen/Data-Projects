# Project Overview
Using Python and its libraries, you will gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. You will document your wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python (and its libraries) and/or SQL.

The dataset that you will be wrangling (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs downloaded their Twitter archive and sent it via email exclusively for you to use in this project. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017.

# Project Steps Overview
Your tasks in this project are as follows:
1. Gather the data
2. Assess the data
3. Clean the data
4. Store the data
5. Analyze and visualize the data
6. Report your data wrangling efforts and your analyses and visualizations

# Libraries Used
Pandas
NumPy
requests
tweepy
json

# Datasets Used
Enhanced WeRateDogs Twitter archive
Addition Data via Twitter API
Image Predictions File
