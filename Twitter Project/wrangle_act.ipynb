{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.6/site-packages (3.5.0)\n",
      "Requirement already satisfied: requests>=2.4.3 in /opt/conda/lib/python3.6/site-packages (from tweepy) (2.18.4)\n",
      "Requirement already satisfied: requests_oauthlib>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tweepy) (0.8.0)\n",
      "Requirement already satisfied: six>=1.7.3 in /opt/conda/lib/python3.6/site-packages (from tweepy) (1.11.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.4.3->tweepy) (2019.11.28)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /opt/conda/lib/python3.6/site-packages (from requests_oauthlib>=0.4.1->tweepy) (2.0.6)\n"
     ]
    }
   ],
   "source": [
    "# Install the twitter API\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import tweepy\n",
    "import requests\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('twitter_archive_enhanced.csv'): #confirm if file not downloaded already\n",
    "    try:\n",
    "        url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv'\n",
    "        urlretrieve(url, 'twitter_archive_enhanced.csv')\n",
    "        print('File saved successfully')\n",
    "    except OSError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive = pd.read_csv('twitter_archive_enhanced.csv')\n",
    "df_archive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"image_predictions.tsv\"):\n",
    "    try:\n",
    "        url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "        page = requests.get(url)\n",
    "        print('Connection sucessful')\n",
    "        with open('image_predictions.tsv', 'wb') as file:\n",
    "            file.write(page.content)\n",
    "            print('File saved successfully')\n",
    "    except OSError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.read_csv('image_predictions.tsv', sep = '\\t')\n",
    "df_image.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = list(df_archive.tweet_id)\n",
    "\n",
    "file_name = 'tweet_ids.txt'\n",
    "with open(file_name, 'w') as f:\n",
    "  for id in tweet_ids:\n",
    "    f.write(f'{str(id)}\\n')\n",
    "\n",
    "'''\n",
    "Test if it can be printed line by line.\n",
    "\n",
    " with open(file_name, 'r') as f:\n",
    "  tweet_ids = f.readline()\n",
    "  print(tweet_ids)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Download tweets with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r'Error: Kindly provide the consumer_key, consumer_screet, access_token, '\n",
    "      'access_screet and bearer_token')\n",
    "\n",
    "#import tweepy\n",
    "#from tweepy import OAuthHandler\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key = \"Your Key Here\"\n",
    "consumer_secret = \"Your Key Here\"\n",
    "access_token = \"Your Key Here\"\n",
    "access_secret = \"Your Key Here\"\n",
    "bearer_token = \"Your Key Here\"\n",
    "\n",
    "#auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Same result as the cell above but data not saved here\n",
    "tweet_ids = df_archive.tweet_id.values\n",
    "len(tweet_ids)\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "start = timer()\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            print(\"Success\")\n",
    "            json.dump(tweet._json, outfile)\n",
    "            outfile.write('\\n')\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "            pass\n",
    "end = timer()\n",
    "print(end - start)\n",
    "print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Read the tweet_json.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for line in open('tweet_json.txt', 'r'):\n",
    "    tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to be used for the analysis\n",
    "id = []\n",
    "favorite_count = []\n",
    "retweet_count = []\n",
    "created_at = []\n",
    "for value in tweets:\n",
    "  id.append(value['id'])\n",
    "  favorite_count.append(value['favorite_count'])\n",
    "  retweet_count.append(value['retweet_count'])\n",
    "  date = time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(value['created_at'],'%a %b %d %H:%M:%S +0000 %Y'))\n",
    "  created_at.append(date)\n",
    "\n",
    "\n",
    "dict = {\n",
    "    'Created_at' : created_at,\n",
    "    'tweet_id' : id,\n",
    "    'favorite_count' : favorite_count,\n",
    "    'retweet_count' : retweet_count,\n",
    "    }\n",
    "\n",
    "df_tweet = pd.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive\n",
    "df_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image\n",
    "df_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet\n",
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = pd.Series(list(df_archive) + list(df_image) + list(df_tweet))\n",
    "all_columns[all_columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['in_reply_to_status_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive['in_reply_to_user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.doggo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.doggo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.pupper.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.source[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.p1_dog.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.p2_dog.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.p3_dog.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "1. Archive table\n",
    "    a. Change the datatype for some of the columns i.e. timestamp\n",
    "    b. A lot of missing data in the features\n",
    "    c. Missing values represented as \"None\"\n",
    "    d. Expanded_url containing more than one url\n",
    "    \n",
    "2. Image table\n",
    "    a. Lowercase for P1, P2, and P3 occassionally\n",
    "    b. Text column not properly formatted\n",
    "\n",
    "3. Tweet table\n",
    "    a. Extract the date from Created_at column\n",
    "    b. Rename the Created_at column as Timestamp to bridge uniformity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1. P1, P2, and P3 should be formatted properly in the Image table\n",
    "\n",
    "2. Remove html tags from the source column in the Archive table\n",
    "\n",
    "3. Tweet_id in the Archive table is duplicated in the Image and Tweet tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n",
    "archive = df_archive.copy()\n",
    "image = df_image.copy()\n",
    "tweet = df_tweet.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1: Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: archive: in_reply_to_status, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, and retweeted_status_timestamp contain little or no meaningful data and should be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive.drop(columns = ['in_reply_to_status_id', 'in_reply_to_user_id','retweeted_status_id', 'retweeted_status_user_id',\n",
    "       'retweeted_status_timestamp'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2: Data Type\n",
    "\n",
    "1. archive: Timestamp is a datetime and not an object\n",
    "2. archive: Tweet_id is an object not an integer\n",
    "3. image: P2_dog is a boolean not an integer\n",
    "4. tweet: Created_at is a datetime and not an integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Change the timestamp datatype to datetime, P2_dog to boolean, and tweet_id to object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive['timestamp'] = pd.to_datetime(archive['timestamp'])\n",
    "archive['tweet_id'] = archive['tweet_id'].astype(str)\n",
    "image['tweet_id'] = image['tweet_id'].astype(str)\n",
    "image['p2_dog'] =  image['p2_dog'].astype(bool)\n",
    "tweet['Created_at'] = pd.to_datetime(tweet['Created_at'])\n",
    "tweet['tweet_id'] = tweet['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Format Column Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Change the created_at to timestamp in tweet table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.rename(columns= {\"Created_at\": \"timestamp\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: Format P1, P2, and P3 in the image table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "Replace \"-\" with space (\" \") for P1, P2, and P3 in the image table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.p1 = image.p1.str.replace(\"_\", \",\")\n",
    "image.p2 = image.p2.str.replace(\"_\", \",\")\n",
    "image.p3 = image.p3.str.replace(\"_\", \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #5: Format the timestamp and source in archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define\n",
    "1. Remove html tags from the source column in the archive table\n",
    "2. Make the timestamp to contain year, month, and day only\n",
    "3. Choose only the expanded_url url that follows the normal pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive['source']  = archive.source.str.extract('(http://\\w+\\.com/\\w+/iphone)', expand = True)\n",
    "archive['expanded_urls']  = archive.expanded_urls.str.extract('(https://\\w+\\.com/\\w+/\\w+/\\d+/\\w+/\\d)', expand = True)\n",
    "\n",
    "archive['timestamp'] = archive['timestamp'].astype(str)\n",
    "tweet['timestamp'] = tweet['timestamp'].astype(str)\n",
    "archive['timestamp'] = archive['timestamp'].str.extract('(\\d{4}[-]\\d{2}[-]\\d{2})', expand = True)\n",
    "tweet['timestamp'] = tweet['timestamp'].str.extract('(\\d{4}[-]\\d{2}[-]\\d{2})', expand = True)\n",
    "archive['timestamp'] = pd.to_datetime(archive['timestamp'])\n",
    "tweet['timestamp'] = pd.to_datetime(tweet['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master = pd.merge(pd.merge(archive, image, on = \"tweet_id\"), tweet, on = \"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It can be observed that both timestamp_x and timestamp_y are the same\n",
    "1. Drop timestamp_y\n",
    "2. Remove x from timestamp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.drop(columns = ['timestamp_y'], inplace= True)\n",
    "twitter_archive_master.rename(columns = {'timestamp_x':'timestamp'}, inplace = True)\n",
    "twitter_archive_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master['month'] = twitter_archive_master.timestamp.dt.month_name()\n",
    "twitter_archive_master['day'] = twitter_archive_master.timestamp.dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.to_csv(\"twitter_archive_master.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**\n",
    "\n",
    "### Questions\n",
    "\n",
    "1. Top ten months with the highest favorite_count\n",
    "2. Top ten months with the hightest tweet_count\n",
    "3. Influence of the day on the favorite_count\n",
    "4. Finding the correlation between the Favorite and Retweet counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights\n",
    "\n",
    "### Write function for the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = twitter_archive_master.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barhplot(x, y, xlabel, title):\n",
    "    plt.figure(figsize=  (14, 8))\n",
    "    plt.barh(x, y, align = 'center')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(xlabel, fontsize = 18)\n",
    "    plt.title(title, fontsize = 18)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ten months with the highest favorite_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df.sort_values(by = 'favorite_count', ascending = False)\n",
    "top_10 = top[['tweet_id', 'source', 'favorite_count', 'month']].head(10)\n",
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barhplot(top_10.month, top_10.favorite_count, \"Favorite Count\", \"Months with the highest favorite count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top ten months with the highest retweet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df.sort_values(by = 'retweet_count', ascending = False)\n",
    "top_10 = top[['tweet_id', 'source', 'text', 'retweet_count', 'month']].head(10)\n",
    "top_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barhplot(top_10.month, top_10.retweet_count, \"Retweet Count\", \"Months with the highest tweet count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influence of the day on the favorite_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = df.groupby(by = 'day')\n",
    "top = df.sort_values(by = 'favorite_count', ascending = False)\n",
    "top_10 = top[['tweet_id', 'source', 'text', 'favorite_count', 'day']].head(10)\n",
    "top_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barhplot(top_10.day, top_10.favorite_count, \"Favorite Count\", \"Influence of the day on the favourite count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the correlation between the Favorite and Retweet counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.favorite_count.corr(df.retweet_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 13))\n",
    "ax = plt.axes()\n",
    "ax.scatter(df.favorite_count, df.retweet_count)\n",
    "\n",
    "ax.set_xlabel('Favorite Count')\n",
    "ax.set_ylabel('Retweet Count')\n",
    "ax.set_title('Correlatiion Between the Favorite and Retweet Counts')\n",
    "\n",
    "ax.axis('tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking for other correlations\n",
    "\n",
    "1. Between favorite_count and rating_numerator\n",
    "2. Between favorite_count and rating_denominator\n",
    "3. Between retweet_count and rating_numerator\n",
    "4. Between retweet_count and rating_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.favorite_count.corr(df.rating_numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.favorite_count.corr(df.rating_denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.retweet_count.corr(df.rating_numerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.retweet_count.corr(df.rating_denominator)"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
